# Optimal Decision-Making with Markov Decision Processes

## üìù Overview
This project explores stochastic decision-making in dynamic environments using Markov Decision Processes (MDPs). It implements key algorithms such as **Value Iteration**, **Policy Iteration**, and **Q-Value Iteration** to derive optimal policies under uncertainty. The project was developed as part of the *Fundamentals of Artificial Intelligence* course (Fall 2025).

## üìÇ Project Structure
- `AI_MDPs.ipynb`: Jupyter Notebook implementing and comparing different MDP solution algorithms.
- Includes grid-based world examples with probabilistic transitions and visualizations of learned policies.

## ‚öôÔ∏è Implemented Algorithms
- **Value Iteration**: Iteratively updates utility values to converge on an optimal policy.
- **Policy Iteration**: Alternates between policy evaluation and improvement to find optimal strategies.
- **Q-Value Iteration**: Approximates the optimal action-value function for decision-making.

## üöÄ How to Run

### Prerequisites
- Python 3.8+
- Jupyter Notebook
- Required libraries: `numpy`, `matplotlib`

### Setup Instructions
1. Clone the repository or download the notebook file.
2. Install dependencies:
   ```bash
   pip install numpy matplotlib
